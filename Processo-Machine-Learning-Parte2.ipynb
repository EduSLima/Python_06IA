{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy</font>\n",
    "# <font color='blue'>Big Data Real-Time Analytics com Python e Spark</font>\n",
    "\n",
    "# <font color='blue'>Capítulo 6</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning em Python - Parte 2 - Regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/processo.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url = 'images/processo.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.20.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn as sl\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sl.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição do Problema de Negócio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar um modelo preditivo que seja capaz de prever o preço de casas com base em uma série de variáveis (características) sobre diversas casas em um bairro de Boston, cidade dos EUA.\n",
    "\n",
    "Dataset: https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando a Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As métricas que você escolhe para avaliar a performance do modelo vão influenciar a forma como a performance é medida e comparada com modelos criados com outros algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas para Algoritmos de Regressão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas Para Avaliar Modelos de Regressão\n",
    "\n",
    "- Mean Squared Error (MSE)\n",
    "- Root Mean Squared Error (RMSE)\n",
    "- Mean Absolute Error (MAE)\n",
    "- R Squared (R²)\n",
    "- Adjusted R Squared (R²)\n",
    "- Mean Square Percentage Error (MSPE)\n",
    "- Mean Absolute Percentage Error (MAPE)\n",
    "- Root Mean Squared Logarithmic Error (RMSLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/mse.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url = 'images/mse.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/rmse.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url = 'images/rmse.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/mae.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url = 'images/mae.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/r2.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url = 'images/r2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vamos agora estudar as métricas para regressão, usaremos outro dataset, o Boston Houses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSE\n",
    "\n",
    "É talvez a métrica mais simples e comum para a avaliação de regressão, mas também provavelmente a menos útil. O MSE basicamente mede o erro quadrado médio de nossas previsões. Para cada ponto, calcula a diferença quadrada entre as previsões e o valor real da variável alvo e, em seguida, calcula a média desses valores.\n",
    "\n",
    "Quanto maior esse valor, pior é o modelo. Esse valor nunca será negativo, já que estamos elevando ao quadrado os erros individuais de previsão, mas seria zero para um modelo perfeito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'data/boston-houses.csv' does not exist: b'data/boston-houses.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aa6a08e1ec5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0marquivo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/boston-houses.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcolunas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'CRIM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ZN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'INDUS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CHAS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NOX'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AGE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DIS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RAD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TAX'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PTRATIO'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LSTAT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MEDV'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdados\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marquivo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelim_whitespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolunas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdados\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'data/boston-houses.csv' does not exist: b'data/boston-houses.csv'"
     ]
    }
   ],
   "source": [
    "# MSE - Mean Squared Error\n",
    "# Similar ao MAE, fornece a magnitude do erro do modelo.\n",
    "# Quanto maior, pior é o modelo!\n",
    "# Ao extrairmos a raiz quadrada do MSE convertemos as unidades de volta ao original, \n",
    "# o que pode ser útil para descrição e apresentação. Isso é chamado RMSE (Root Mean Squared Error)\n",
    "\n",
    "# Import dos módulos\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Carregando os dados\n",
    "arquivo = 'data/boston-houses.csv'\n",
    "colunas = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO','B', 'LSTAT', 'MEDV']\n",
    "dados = read_csv(arquivo, delim_whitespace = True, names = colunas)\n",
    "array = dados.values\n",
    "\n",
    "# Separando o array em componentes de input e output\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "\n",
    "# Divide os dados em treino e teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 5)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = LinearRegression()\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo.fit(X_train, Y_train)\n",
    "\n",
    "# Fazendo previsões\n",
    "Y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Resultado\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "print(\"O MSE do modelo é:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O MAE do modelo é: 3.455034932248351\n"
     ]
    }
   ],
   "source": [
    "# MAE\n",
    "# Mean Absolute Error\n",
    "# É a soma da diferença absoluta entre previsões e valores reais.\n",
    "# Fornece uma ideia de quão erradas estão nossas previsões.\n",
    "# Valor igual a 0 indica que não há erro, sendo a previsão perfeita.\n",
    "\n",
    "# Import dos módulos\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Carregando os dados\n",
    "arquivo = 'data/boston-houses.csv'\n",
    "colunas = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO','B', 'LSTAT', 'MEDV']\n",
    "dados = read_csv(arquivo, delim_whitespace = True, names = colunas)\n",
    "array = dados.values\n",
    "\n",
    "# Separando o array em componentes de input e output\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "\n",
    "# Divide os dados em treino e teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 5)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = LinearRegression()\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo.fit(X_train, Y_train)\n",
    "\n",
    "# Fazendo previsões\n",
    "Y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Resultado\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "print(\"O MAE do modelo é:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O R2 do modelo é: 0.6956551656111596\n"
     ]
    }
   ],
   "source": [
    "# R^2\n",
    "# Essa métrica fornece uma indicação do nível de precisão das previsões em relação aos valores observados.\n",
    "# Também chamado de coeficiente de determinação.\n",
    "# Valores entre 0 e 1, sendo 0 o valor ideal.\n",
    "\n",
    "# Import dos módulos\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Carregando os dados\n",
    "arquivo = 'data/boston-houses.csv'\n",
    "colunas = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO','B', 'LSTAT', 'MEDV']\n",
    "dados = read_csv(arquivo, delim_whitespace = True, names = colunas)\n",
    "array = dados.values\n",
    "\n",
    "# Separando o array em componentes de input e output\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "\n",
    "# Divide os dados em treino e teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 5)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = LinearRegression()\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo.fit(X_train, Y_train)\n",
    "\n",
    "# Fazendo previsões\n",
    "Y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Resultado\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "print(\"O R2 do modelo é:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos de Regressão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume que os dados estão em Distribuição Normal e também assume que as variáveis são relevantes para a construção do modelo e que não sejam colineares, ou seja, variáveis com alta correlação (cabe a você, Cientista de Dados, entregar ao algoritmo as variáveis realmente relevantes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O MSE do modelo é: 28.53045876597469\n"
     ]
    }
   ],
   "source": [
    "# Import dos módulos\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Carregando os dados\n",
    "arquivo = 'data/boston-houses.csv'\n",
    "colunas = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO','B', 'LSTAT', 'MEDV']\n",
    "dados = read_csv(arquivo, delim_whitespace = True, names = colunas)\n",
    "array = dados.values\n",
    "\n",
    "# Separando o array em componentes de input e output\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "\n",
    "# Divide os dados em treino e teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 5)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = LinearRegression()\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo.fit(X_train, Y_train)\n",
    "\n",
    "# Fazendo previsões\n",
    "Y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Resultado\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "print(\"O MSE do modelo é:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extensão para a regressão linear onde a loss function é modificada para minimizar a complexidade do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O MSE do modelo é: 29.29406201348501\n"
     ]
    }
   ],
   "source": [
    "# Import dos módulos\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Carregando os dados\n",
    "arquivo = 'data/boston-houses.csv'\n",
    "colunas = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO','B', 'LSTAT', 'MEDV']\n",
    "dados = read_csv(arquivo, delim_whitespace = True, names = colunas)\n",
    "array = dados.values\n",
    "\n",
    "# Separando o array em componentes de input e output\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "\n",
    "# Divide os dados em treino e teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 5)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = Ridge()\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo.fit(X_train, Y_train)\n",
    "\n",
    "# Fazendo previsões\n",
    "Y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Resultado\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "print(\"O MSE do modelo é:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso (Least Absolute Shrinkage and Selection Operator) Regression é uma modificação da regressão linear e assim como a Ridge Regression, a loss function é modificada para minimizar a complexidade do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O MSE do modelo é: 33.39451439004989\n"
     ]
    }
   ],
   "source": [
    "# Import dos módulos\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Carregando os dados\n",
    "arquivo = 'data/boston-houses.csv'\n",
    "colunas = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO','B', 'LSTAT', 'MEDV']\n",
    "dados = read_csv(arquivo, delim_whitespace = True, names = colunas)\n",
    "array = dados.values\n",
    "\n",
    "# Separando o array em componentes de input e output\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "\n",
    "# Divide os dados em treino e teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 5)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = Lasso()\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo.fit(X_train, Y_train)\n",
    "\n",
    "# Fazendo previsões\n",
    "Y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Resultado\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "print(\"O MSE do modelo é:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ElasticNet é uma forma de regularização da regressão que combina as propriedades da regressão Ridge e LASSO. O objetivo é minimizar a complexidade do modelo, penalizando o modelo usando a soma dos quadrados dos coeficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O MSE do modelo é: 33.27255150876939\n"
     ]
    }
   ],
   "source": [
    "# Import dos módulos\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Carregando os dados\n",
    "arquivo = 'data/boston-houses.csv'\n",
    "colunas = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO','B', 'LSTAT', 'MEDV']\n",
    "dados = read_csv(arquivo, delim_whitespace = True, names = colunas)\n",
    "array = dados.values\n",
    "\n",
    "# Separando o array em componentes de input e output\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "\n",
    "# Divide os dados em treino e teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 5)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = ElasticNet()\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo.fit(X_train, Y_train)\n",
    "\n",
    "# Fazendo previsões\n",
    "Y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Resultado\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "print(\"O MSE do modelo é:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O MSE do modelo é: 47.70591377245509\n"
     ]
    }
   ],
   "source": [
    "# Import dos módulos\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Carregando os dados\n",
    "arquivo = 'data/boston-houses.csv'\n",
    "colunas = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO','B', 'LSTAT', 'MEDV']\n",
    "dados = read_csv(arquivo, delim_whitespace = True, names = colunas)\n",
    "array = dados.values\n",
    "\n",
    "# Separando o array em componentes de input e output\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "\n",
    "# Divide os dados em treino e teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 5)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = KNeighborsRegressor()\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo.fit(X_train, Y_train)\n",
    "\n",
    "# Fazendo previsões\n",
    "Y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Resultado\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "print(\"O MSE do modelo é:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O MSE do modelo é: 35.32329341317365\n"
     ]
    }
   ],
   "source": [
    "# Import dos módulos\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Carregando os dados\n",
    "arquivo = 'data/boston-houses.csv'\n",
    "colunas = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO','B', 'LSTAT', 'MEDV']\n",
    "dados = read_csv(arquivo, delim_whitespace = True, names = colunas)\n",
    "array = dados.values\n",
    "\n",
    "# Separando o array em componentes de input e output\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "\n",
    "# Divide os dados em treino e teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 5)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = DecisionTreeRegressor()\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo.fit(X_train, Y_train)\n",
    "\n",
    "# Fazendo previsões\n",
    "Y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Resultado\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "print(\"O MSE do modelo é:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O MSE do modelo é: 93.21909995717193\n"
     ]
    }
   ],
   "source": [
    "# Import dos módulos\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Carregando os dados\n",
    "arquivo = 'data/boston-houses.csv'\n",
    "colunas = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO','B', 'LSTAT', 'MEDV']\n",
    "dados = read_csv(arquivo, delim_whitespace = True, names = colunas)\n",
    "array = dados.values\n",
    "\n",
    "# Separando o array em componentes de input e output\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "\n",
    "# Divide os dados em treino e teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 5)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = SVR()\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo.fit(X_train, Y_train)\n",
    "\n",
    "# Fazendo previsões\n",
    "Y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Resultado\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "print(\"O MSE do modelo é:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização do Modelo - Ajuste de Parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos os algoritmos de Machine Learning são parametrizados, o que significa que você pode ajustar a performance do seu modelo preditivo, através do tuning (ajuste fino) dos parâmetros. Seu trabalho é encontrar a melhor combinação entre os parâmetros em cada algoritmo de Machine Learning. Esse processo também é chamado de Otimização Hyperparâmetro. O scikit-learn oferece dois métodos para otimização automática dos parâmetros: Grid Search Parameter Tuning e Random Search Parameter Tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este método realiza metodicamente combinações entre todos os parâmetros do algoritmo, criando um grid. Vamos experimentar este método utilizando o algoritmo de Regressão Ridge. No exemplo abaixo veremos que o valor 1 para o parâmetro alpha atingiu a melhor performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores Parâmetros do Modelo:\n",
      " Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n"
     ]
    }
   ],
   "source": [
    "# Import dos módulos\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Carregando os dados\n",
    "arquivo = 'data/boston-houses.csv'\n",
    "colunas = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO','B', 'LSTAT', 'MEDV']\n",
    "dados = read_csv(arquivo, delim_whitespace = True, names = colunas)\n",
    "array = dados.values\n",
    "\n",
    "# Separando o array em componentes de input e output\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "# Definindo os valores que serão testados\n",
    "valores_alphas = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "valores_grid = dict(alpha = valores_alphas)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = Ridge()\n",
    "\n",
    "# Criando o grid\n",
    "grid = GridSearchCV(estimator = modelo, param_grid = valores_grid)\n",
    "grid.fit(X, Y)\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Melhores Parâmetros do Modelo:\\n\", grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este método gera amostras dos parâmetros dos algoritmos a partir de uma distribuição randômica uniforme para um número fixo de interações. Um modelo é construído e testado para cada combinação de parâmetros. Neste exemplo veremos que o valor muito próximo de 1 para o parâmetro alpha é o que vai apresentar os melhores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores Parâmetros do Modelo:\n",
      " Ridge(alpha=0.9779895119966027, copy_X=True, fit_intercept=True,\n",
      "   max_iter=None, normalize=False, random_state=None, solver='auto',\n",
      "   tol=0.001)\n"
     ]
    }
   ],
   "source": [
    "# Import dos módulos\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from scipy.stats import uniform\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Carregando os dados\n",
    "arquivo = 'data/boston-houses.csv'\n",
    "colunas = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO','B', 'LSTAT', 'MEDV']\n",
    "dados = read_csv(arquivo, delim_whitespace = True, names = colunas)\n",
    "array = dados.values\n",
    "\n",
    "# Separando o array em componentes de input e output\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "# Definindo os valores que serão testados\n",
    "valores_grid = {'alpha': uniform()}\n",
    "seed = 7\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = Ridge()\n",
    "iterations = 100\n",
    "rsearch = RandomizedSearchCV(estimator = modelo, \n",
    "                             param_distributions = valores_grid, \n",
    "                             n_iter = iterations, \n",
    "                             random_state = seed)\n",
    "rsearch.fit(X, Y)\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Melhores Parâmetros do Modelo:\\n\", rsearch.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando o resultado do seu trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo salvo!\n",
      "Modelo carregado!\n",
      "O MSE do modelo é: 27.32316713717489\n"
     ]
    }
   ],
   "source": [
    "# Import dos módulos\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "import pickle\n",
    "\n",
    "# Carregando os dados\n",
    "arquivo = 'data/boston-houses.csv'\n",
    "colunas = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO','B', 'LSTAT', 'MEDV']\n",
    "dados = read_csv(arquivo, delim_whitespace = True, names = colunas)\n",
    "array = dados.values\n",
    "\n",
    "# Separando o array em componentes de input e output\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "\n",
    "# Definindo os valores para o número de folds\n",
    "teste_size = 0.35\n",
    "seed = 7\n",
    "\n",
    "# Criando o dataset de treino e de teste\n",
    "X_treino, X_teste, Y_treino, Y_teste = train_test_split(X, Y, test_size = teste_size, random_state = seed)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = Ridge()\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo.fit(X_treino, Y_treino)\n",
    "\n",
    "# Salvando o modelo\n",
    "arquivo = 'modelos/modelo_regressor_final.sav'\n",
    "pickle.dump(modelo, open(arquivo, 'wb'))\n",
    "print(\"Modelo salvo!\")\n",
    "\n",
    "# Carregando o arquivo\n",
    "modelo_regressor_final = pickle.load(open(arquivo, 'rb'))\n",
    "print(\"Modelo carregado!\")\n",
    "\n",
    "# Print do resultado\n",
    "# Fazendo previsões\n",
    "Y_pred = modelo_regressor_final.predict(X_test)\n",
    "\n",
    "# Resultado\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "print(\"O MSE do modelo é:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obrigado - Data Science Academy - <a href=\"http://facebook.com/dsacademybr\">facebook.com/dsacademybr</a>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
